# Awesome-LLM-Dev-Notes

ğŸš€ ç²¾é€‰å¤§æ¨¡å‹ (LLM) å¼€å‘é¢†åŸŸçš„é«˜è´¨é‡æŠ€æœ¯æ–‡ç« ã€å®æˆ˜ç»éªŒä¸å­¦ä¹ ç¬”è®°ã€‚/ Curated list of high-quality LLM development articles, practical experiences, and notes.

## ç›®å½• / Contents

### æ¨ç†ä¼˜åŒ– (Inference Optimization)

- [Flash-Decoding: é•¿ä¸Šä¸‹æ–‡æ¨ç†åŠ é€Ÿ](./notes/inference/Flash-Decoding.md) (2023-10-12)
  - é’ˆå¯¹é•¿ Context æ¨ç†åœºæ™¯ï¼Œé€šè¿‡å¹¶è¡ŒåŒ– KV Cache ç»´åº¦æå‡ Attention è®¡ç®—æ•ˆç‡ã€‚
